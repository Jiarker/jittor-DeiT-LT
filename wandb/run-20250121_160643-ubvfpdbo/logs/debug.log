2025-01-21 16:06:43,179 INFO    MainThread:1465683 [wandb_setup.py:_flush():68] Current SDK version is 0.19.4
2025-01-21 16:06:43,179 INFO    MainThread:1465683 [wandb_setup.py:_flush():68] Configure stats pid to 1465683
2025-01-21 16:06:43,179 INFO    MainThread:1465683 [wandb_setup.py:_flush():68] Loading settings from /root/.config/wandb/settings
2025-01-21 16:06:43,180 INFO    MainThread:1465683 [wandb_setup.py:_flush():68] Loading settings from /home/ubuntu/code/myf/jittor-DeiT-LT/wandb/settings
2025-01-21 16:06:43,180 INFO    MainThread:1465683 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-01-21 16:06:43,180 INFO    MainThread:1465683 [wandb_init.py:setup_run_log_directory():624] Logging user logs to /home/ubuntu/code/myf/jittor-DeiT-LT/wandb/run-20250121_160643-ubvfpdbo/logs/debug.log
2025-01-21 16:06:43,180 INFO    MainThread:1465683 [wandb_init.py:setup_run_log_directory():625] Logging internal logs to /home/ubuntu/code/myf/jittor-DeiT-LT/wandb/run-20250121_160643-ubvfpdbo/logs/debug-internal.log
2025-01-21 16:06:43,180 INFO    MainThread:1465683 [wandb_init.py:init():743] calling init triggers
2025-01-21 16:06:43,180 INFO    MainThread:1465683 [wandb_init.py:init():748] wandb.init called with sweep_config: {}
config: {}
2025-01-21 16:06:43,180 INFO    MainThread:1465683 [wandb_init.py:init():776] starting backend
2025-01-21 16:06:43,460 INFO    MainThread:1465683 [wandb_init.py:init():780] sending inform_init request
2025-01-21 16:06:43,592 INFO    MainThread:1465683 [backend.py:_multiprocessing_setup():97] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-01-21 16:06:43,593 INFO    MainThread:1465683 [wandb_init.py:init():795] backend started and connected
2025-01-21 16:06:43,600 INFO    MainThread:1465683 [wandb_init.py:init():888] updated telemetry
2025-01-21 16:06:43,661 INFO    MainThread:1465683 [wandb_init.py:init():915] communicating run to backend with 90.0 second timeout
2025-01-21 16:06:44,345 INFO    MainThread:1465683 [wandb_init.py:init():967] starting run threads in backend
2025-01-21 16:06:44,558 INFO    MainThread:1465683 [wandb_run.py:_console_start():2409] atexit reg
2025-01-21 16:06:44,559 INFO    MainThread:1465683 [wandb_run.py:_redirect():2259] redirect: wrap_raw
2025-01-21 16:06:44,559 INFO    MainThread:1465683 [wandb_run.py:_redirect():2324] Wrapping output streams.
2025-01-21 16:06:44,559 INFO    MainThread:1465683 [wandb_run.py:_redirect():2349] Redirects installed.
2025-01-21 16:06:44,567 INFO    MainThread:1465683 [wandb_init.py:init():1009] run started, returning control to user process
2025-01-21 16:06:45,555 INFO    MainThread:1465683 [wandb_run.py:_config_callback():1270] config_cb None None {'project_name': 'DeiT-LT', 'batch_size': 32, 'epochs': 1200, 'gpu': 0, 'unscale_lr': False, 'log_results': True, 'bce_loss': False, 'accum_iter': 4, 'drop_last': False, 'model': 'deit_base_distilled_patch16_224', 'input_size': 224, 'teacher_size': 32, 'drop': 0.0, 'drop_path': 0.1, 'local_global_teacher': False, 'model_ema': True, 'adl': False, 'model_ema_decay': 0.99996, 'model_ema_force_cpu': False, 'custom_model': True, 'opt': 'adamw', 'opt_eps': 1e-08, 'opt_betas': None, 'clip_grad': None, 'momentum': 0.9, 'weight_decay': 0.05, 'sched': 'cosine', 'lr': 0.0005, 'lr_noise': None, 'lr_noise_pct': 0.67, 'lr_noise_std': 1.0, 'warmup_lr': 1e-06, 'min_lr': 1e-05, 'decay_epochs': 30, 'warmup_epochs': 5, 'cooldown_epochs': 10, 'patience_epochs': 10, 'decay_rate': 0.1, 'color_jitter': 0.3, 'aa': 'rand-m9-mstd0.5-inc1', 'smoothing': 0.1, 'train_interpolation': 2, 'repeated_aug': True, 'rand_aug': False, 'ThreeAugment': False, 'src': False, 'reprob': 0.25, 'remode': 'pixel', 'recount': 1, 'resplit': False, 'mixup': 0.8, 'cutmix': 1.0, 'cutmix_minmax': None, 'mixup_prob': 1.0, 'mixup_switch_prob': 0.5, 'mixup_mode': 'batch', 'no_mixup_drw': True, 'student_path': None, 'teacher_model': 'resnet32', 'teacher_path': 'pretrained/teacher_pretrained/cf100_100_teacher.pth', 'distillation_type': 'hard', 'distillation_alpha': 0.5, 'distillation_tau': 1.0, 'finetune': '', 'attn_only': False, 'data_path': 'data/CIFAR100', 'data_set': 'CIFAR100LT', 'inat_category': 'name', 'output_dir': 'deit_out_c100lt/deit_base_distilled_patch16_224_resnet32_1200_CIFAR100LT_imb100_32_[jittor_sam_cifar100_if100]', 'save_freq': 300, 'eval_freq': 10, 'device': 'cuda', 'seed': 0, 'resume': '', 'start_epoch': 0, 'eval': False, 'dist_eval': False, 'num_workers': 10, 'pin_mem': True, 'world_size': 1, 'dist_url': 'env://', 'imb_type': 'exp', 'imb_factor': 0.01, 'weighted_distillation': True, 'weighted_baseloss': False, 'drw': 1100, 'use_norm': False, 'student_transform': 0, 'teacher_transform': 0, 'experiment': '[jittor_sam_cifar100_if100]', 'map_targets': False, 'beta': 0.9999, 'mask_attn': False, 'early_stopping': False, 'transmix': False, 'no_distillation': False, 'moco_dim': 32, 'moco_k': 1024, 'moco_m': 0.999, 'moco_t': 0.05, 'normalize': False, 'mlp': True, 'feat_dim': 64, 'paco': True, 'multi_crop': False, 'global_crops_scale': [0.4, 1.0], 'local_crops_number': 8, 'local_crops_scale': [0.05, 0.4], 'name_exp': 'deit_base_distilled_patch16_224_resnet32_1200_CIFAR100LT_imb100_32_[jittor_sam_cifar100_if100]'}
